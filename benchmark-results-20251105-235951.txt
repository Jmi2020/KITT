===========================================
llama.cpp GPU Benchmark
===========================================
Host: http://localhost:8080
Model: kitty-primary
Date: Wed Nov  5 23:59:51 PST 2025

Server is responding. Starting benchmark tests...

Test: short-prompt
Prompt length: 30 chars
Generating 64 tokens...
ERROR: Failed to generate tokens
Response: {"detail":"Not Found"}

Test: medium-prompt
Prompt length: 175 chars
Generating 128 tokens...
ERROR: Failed to generate tokens
Response: {"detail":"Not Found"}

Test: long-prompt
Prompt length: 2771 chars
Generating 128 tokens...
ERROR: Failed to generate tokens
Response: {"detail":"Not Found"}

Test: generation-test
Prompt length: 67 chars
Generating 256 tokens...
ERROR: Failed to generate tokens
Response: {"detail":"Not Found"}

===========================================
Benchmark Complete
Results saved to: benchmark-results-20251105-235951.txt
===========================================

GPU Metrics Summary:
  generation-test:
    No GPU metrics captured
  long-prompt:
    No GPU metrics captured
  medium-prompt:
    No GPU metrics captured
  short-prompt:
    No GPU metrics captured
