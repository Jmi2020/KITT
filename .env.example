# KITTY core identity & safety
USER_NAME=YourName
KITTY_USER_NAME=YourName
KITTY_USER_ID=0000
PRIMARY_LOCALE=en-US
VERBOSITY=3
OFFLINE_MODE=false
CONFIDENCE_THRESHOLD=0.80
BUDGET_PER_TASK_USD=0.50
ENABLE_FUNCTION_CALLING=true
API_AUTO_APPROVE=true
API_OVERRIDE_PASSWORD=changeme
HAZARD_CONFIRMATION_PHRASE="Confirm: proceed"
TOPIC_PREFIX=kitty
ZONES=welding_bay,printer_bay,laser_room,warehouse

# Routing + providers
LOCAL_REASONER_PROVIDER=ollama

# ==============================================================================
# Parallel Agent Orchestration
# Enables multi-agent parallel execution for complex queries
# See: Research/ParallelAgentExecution.md
# ==============================================================================
ENABLE_PARALLEL_AGENTS=true
PARALLEL_AGENT_ROLLOUT_PERCENT=100
PARALLEL_AGENT_MAX_TASKS=6
PARALLEL_AGENT_MAX_CONCURRENT=8
PARALLEL_AGENT_COMPLEXITY_THRESHOLD=0.6

# Semantic tool selection (embedding-based, ~90% context savings)
USE_SEMANTIC_TOOL_SELECTION=true
EMBEDDING_MODEL=all-MiniLM-L6-v2
TOOL_SEARCH_TOP_K=5
TOOL_SEARCH_THRESHOLD=0.3

# Cloud provider keys (replace with your own; do not commit secrets)
OPENAI_API_KEY=your_openai_key
ANTHROPIC_API_KEY=your_anthropic_key
GOOGLE_API_KEY=your_google_key
PERPLEXITY_API_KEY=your_perplexity_key
ZOO_API_KEY=your_zoo_key
ZOO_API_BASE=https://api.zoo.dev
TRIPO_API_KEY=your_tripo_key
TRIPO_CLIENT_ID=your_tripo_client_id
TRIPO_API_BASE=https://api.tripo3d.ai/v2/openapi
BRAVE_SEARCH_API_KEY=your_brave_key
BRAVE_SEARCH_ENDPOINT=https://api.search.brave.com/res/v1/web/search
JINA_API_KEY=your_jina_key
JINA_READER_BASE_URL=https://r.jina.ai
JINA_READER_DISABLED=true
HOME_ASSISTANT_TOKEN=your_home_assistant_long_lived_token

# ==============================================================================
# Ollama Reasoning Model (GPTOSS 120B) - PRIMARY REASONING ENGINE
# ==============================================================================
# GPTOSS 120B is the primary reasoning model with thinking mode support.
# It replaces the previous Llama 3.3 70B F16 (llama.cpp) reasoner.
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=gpt-oss-120b-judge
OLLAMA_THINK=medium                # Thinking effort: low | medium | high
OLLAMA_TIMEOUT_S=1200              # Extended timeout for reasoning tasks
OLLAMA_KEEP_ALIVE=30m              # Keep model loaded in memory

# llama.cpp models (local)
MODEL_BASE=/path/to/models
LLAMACPP_CTX=8192
LLAMACPP_N_GPU_LAYERS=35
LLAMACPP_THREADS=16
LLAMACPP_FLASH_ATTN=1
LLAMACPP_BATCH_SIZE=4096
LLAMACPP_UBATCH_SIZE=1024
LLAMACPP_PARALLEL=2
LLAMACPP_PRIMARY_MODEL=llama-3-70b/Llama-3.3-70B-Instruct-F16/Llama-3.3-70B-Instruct-F16-00001-of-00004.gguf
LLAMACPP_PRIMARY_ALIAS=kitty-primary
LLAMACPP_CODER_MODEL=Qwen2.5-Coder-32B-Instruct-GGUF/qwen2.5-coder-32b-instruct-q8_0.gguf
LLAMACPP_CODER_ALIAS=kitty-coder

# Q4 (tool orchestrator)
LLAMACPP_Q4_HOST=http://localhost:8083
LLAMACPP_Q4_ALIAS=kitty-q4
LLAMACPP_Q4_MODEL=athene-v2-agent/Athene-V2-Agent-Q4_K_M.gguf
LLAMACPP_Q4_TEMPERATURE=0.0
LLAMACPP_Q4_PORT=8083
LLAMACPP_Q4_CTX=131072
LLAMACPP_Q4_PARALLEL=6
LLAMACPP_Q4_BATCH_SIZE=4096
LLAMACPP_Q4_UBATCH_SIZE=1024
LLAMACPP_Q4_N_GPU_LAYERS=999
LLAMACPP_Q4_THREADS=16
LLAMACPP_Q4_FLASH_ATTN=1
LLAMACPP_Q4_IDLE_SHUTDOWN_SECONDS=900  # 15 min idle -> shutdown to free VRAM

# ==============================================================================
# DEPRECATED: Deep Reasoner fallback (llama.cpp Llama 3.3 70B)
# The primary reasoning model is now GPTOSS 120B via Ollama (see OLLAMA_* above).
# These llama.cpp settings are only used when LOCAL_REASONER_PROVIDER=llamacpp.
# The "F16" name is a legacy reference to the original quantization format.
# In code, use which="DEEP" to access the deep reasoner (routes to kitty-f16 alias).
# ==============================================================================
LLAMACPP_F16_HOST=http://localhost:8082
LLAMACPP_F16_ALIAS=kitty-f16  # Legacy alias name, routes to GPTOSS 120B or llama.cpp fallback
LLAMACPP_F16_MODEL=llama-3-70b/Llama-3.3-70B-Instruct-F16/Llama-3.3-70B-Instruct-F16-00001-of-00004.gguf
LLAMACPP_F16_TEMPERATURE=0.2
LLAMACPP_F16_PORT=8082
LLAMACPP_F16_CTX=131072
LLAMACPP_F16_PARALLEL=1

# Summary
LLAMACPP_SUMMARY_MODEL=Hermes-3-8B/Hermes-3-Llama-3.1-8B.Q4_K_M.gguf
LLAMACPP_SUMMARY_ALIAS=kitty-summary
LLAMACPP_SUMMARY_PORT=8084
LLAMACPP_SUMMARY_IDLE_SHUTDOWN_SECONDS=1800  # 30 min idle -> shutdown

# Coder Server (for parallel agent orchestration)
LLAMACPP_CODER_ENABLED=true
LLAMACPP_CODER_MODEL=Qwen2.5-Coder-32B-Instruct-GGUF/qwen2.5-coder-32b-instruct-q8_0.gguf
LLAMACPP_CODER_HOST=http://localhost:8087
LLAMACPP_CODER_ALIAS=kitty-coder
LLAMACPP_CODER_PORT=8087
LLAMACPP_CODER_CTX=32768
LLAMACPP_CODER_PARALLEL=4
LLAMACPP_CODER_TEMPERATURE=0.2
LLAMACPP_CODER_IDLE_SHUTDOWN_SECONDS=900  # 15 min idle -> shutdown

# Vision
LLAMACPP_VISION_ENABLED=1
LLAMACPP_VISION_MODEL=gemma-3-27b-it-GGUF/gemma-3-27b-it-q4_k_m.gguf
LLAMACPP_VISION_MMPROJ=gemma3_27b_mmproj/mmproj-model-f16.gguf
LLAMACPP_VISION_ALIAS=kitty-vision
LLAMACPP_VISION_PORT=8086
LLAMACPP_VISION_CTX=8192
LLAMACPP_VISION_PARALLEL=2
LLAMACPP_VISION_TEMPERATURE=0.0
LLAMACPP_VISION_BATCH_SIZE=1024
LLAMACPP_VISION_UBATCH_SIZE=256
LLAMACPP_VISION_N_GPU_LAYERS=999
LLAMACPP_VISION_THREADS=12
LLAMACPP_VISION_FLASH_ATTN=1
LLAMACPP_VISION_IDLE_SHUTDOWN_SECONDS=1800  # 30 min idle -> shutdown

# CAD service
CAD_SERVICE_URL=http://cad:8200
CAD_BASE=http://cad:8200
ARTIFACT_RENAME_ENABLED=true

# Voice service
VOICE_BASE_URL=http://host.docker.internal:8410
VOICE_PREFER_LOCAL=true
WHISPER_MODEL=base.en
WHISPER_MODEL_PATH=
PIPER_MODEL_DIR=/path/to/piper/models
OPENAI_TTS_MODEL=tts-1
VOICE_DEFAULT_VOICE=alloy
VOICE_SAMPLE_RATE=16000

# Services & storage
DATABASE_URL=postgresql://kitty:changeme@postgres:5432/kitty
RABBITMQ_URL=amqp://kitty:changeme@rabbitmq:5672/
RABBITMQ_USER=kitty
RABBITMQ_PASSWORD=changeme
RABBITMQ_VHOST=/
RABBITMQ_ERLANG_COOKIE=kitty_secret_cookie_change_me

REDIS_URL=redis://127.0.0.1:6379/0
REDIS_PASSWORD=
REDIS_SENTINEL_PASSWORD=

MINIO_ENDPOINT=http://minio:9000
MINIO_BUCKET=kitty-artifacts
MINIO_ACCESS_KEY=
MINIO_SECRET_KEY=

# Observability / optional
PROMETHEUS_PORT=9090
GRAFANA_PORT=3000
LOKI_PORT=3100
TEMPO_PORT=3200
