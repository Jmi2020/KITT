# noqa: D401
"""Unified system prompt builder for KITTY interfaces.

This module provides a consistent system prompt architecture across all KITTY
interfaces (CLI, voice, agent) with hallucination prevention, tool calling
best practices, and confidence-based decision making.

Based on:
- Research/ToolCallingPrompts.md best practices
- VOICE_SYSTEM_PROMPT from .env
- services/brain/src/brain/prompts/expert_system.py patterns
"""

from __future__ import annotations

import logging
import os
import re
from datetime import datetime, timezone
from string import Formatter
from typing import Any, Dict, List, Optional, Tuple

from common.config import settings
from ..utils.tokens import count_tokens

# Prompt section imports
from .tool_formatter import format_tools_for_prompt, format_tools_compact


class KittySystemPrompt:
    """Unified system prompt builder for all KITTY interfaces.

    This class builds system prompts that are:
    1. Consistent across CLI, voice, and agent modes
    2. Halluc

ination-resistant with explicit constraints
    3. Tool calling compatible with proper JSON formatting
    4. Confidence-based with decision frameworks
    5. Temperature-aware (temp=0 for tool calling)

    Example:
        >>> builder = KittySystemPrompt(settings)
        >>> prompt = builder.build(mode="cli", verbosity=3)
        >>> prompt = builder.build(mode="agent", tools=tools, model_format="qwen")
    """

    def __init__(self, config: Optional[Any] = None):
        """Initialize unified prompt builder.

        Args:
            config: Settings object (uses common.config.settings if not provided)
        """
        self.config = config or settings

        # Load prompt sections
        self._identity = self._load_identity()
        self._hallucination_prevention = self._load_hallucination_prevention()
        self._reasoning_framework = self._load_reasoning_framework()
        self._routing_policy = self._load_routing_policy()
        self._safety_model = self._load_safety_model()

    def build(
        self,
        mode: str = "cli",
        tools: Optional[List[Dict[str, Any]]] = None,
        verbosity: int = 3,
        model_format: str = "qwen",
        context: Optional[str] = None,
        query: Optional[str] = None,
        history: Optional[List[Any]] = None,
        freshness_required: bool = False,
        vision_targets: Optional[List[str]] = None,
    ) -> str:
        """Build unified system prompt for specific interface and model.

        Args:
            mode: Interface mode - "cli", "voice", or "agent"
            tools: Available tools (if any)
            verbosity: Response verbosity level (1-5)
            model_format: Model format for tool calling (qwen, hermes, llama, athene)
            context: Optional context from memory/history
            query: Optional user query (for agent mode)
            history: Optional reasoning history (for agent mode)

        Returns:
            Complete system prompt string

        Example:
            >>> builder = KittySystemPrompt()
            >>> cli_prompt = builder.build(mode="cli", verbosity=3)
            >>> agent_prompt = builder.build(
            ...     mode="agent",
            ...     tools=tool_definitions,
            ...     model_format="qwen",
            ...     query="Search for Python news"
            ... )
        """
        sections: List[Tuple[str, str]] = []

        timestamp_iso, timestamp_human = self._current_time_strings()

        # 1. Identity & Mission
        sections.append(("identity", self._identity))

        # 2. Hallucination Prevention (CRITICAL - always include)
        sections.append(("hallucination_prevention", self._hallucination_prevention))

        # 3. Decision Framework (chain-of-thought)
        sections.append(("reasoning_framework", self._reasoning_framework))

        # 4. Tool Calling Format (if tools provided)
        tool_section_text = ""
        tool_format_text = ""
        if tools:
            tool_section_text = self._build_tool_section(tools, model_format)
            tool_format_text = self._build_tool_calling_format(model_format)
            sections.append(("tool_definitions", tool_section_text))
            sections.append(("tool_format", tool_format_text))

        # 5. Mode-Specific Sections
        if mode == "voice":
            sections.append(("mode_voice", self._build_voice_ux(verbosity)))
        elif mode == "agent":
            sections.append(
                (
                    "mode_agent",
                    self._build_react_pattern(
                        query, history, timestamp_human, timestamp_iso, freshness_required
                    )
                )
            )
        else:  # cli mode
            sections.append(("mode_cli", self._build_cli_ux(verbosity)))

        # 6. Routing Policy & Safety (always include)
        sections.append(("routing_policy", self._routing_policy))
        sections.append(("safety", self._safety_model))

        # 7. Verbosity Instructions
        sections.append(("verbosity", self._build_verbosity_section(verbosity)))

        # 8. Vision plan (if requested)
        if vision_targets:
            sections.append(("vision_plan", self._build_vision_section(vision_targets)))

        # 9. Context (if provided)
        if context:
            sections.append(("context", f"\n<relevant_context>\n{context}\n</relevant_context>\n"))

        # Join all sections with double newlines
        prompt = "\n\n".join(text for _, text in sections if text)

        if query and mode != "agent":
            freshness_note = ""
            if freshness_required:
                freshness_note = (
                    "\nFreshness requirement: This request needs up-to-date information. "
                    "Verify answers with live tools (e.g., web_search) instead of relying solely on training data."
                )
            user_query_text = (
                f"<user_query utc_timestamp=\"{timestamp_iso}\">\n"
                f"Current datetime: {timestamp_human} (UTC){freshness_note}\n"
                f"{query}\n"
                f"</user_query>"
            )
            sections.append(("user_query", user_query_text))
            prompt = f"{prompt}\n\n{user_query_text}" if prompt else user_query_text

        # Perform environment variable substitution
        prompt = self._substitute_env_vars(prompt)
        if os.getenv("PROMPT_TOKEN_LOG", "").lower() in {"1", "true", "yes"}:
            breakdown = {name: count_tokens(text) for name, text in sections if text}
            breakdown["total"] = count_tokens(prompt)
            logging.getLogger("brain.prompt_budget").info("Prompt token breakdown: %s", breakdown)

        return prompt

    def _load_identity(self) -> str:
        """Load KITTY identity section."""
        return """# KITTY - Warehouse Fabrication AI Assistant

## Identity
- **Name**: KITTY (KITT-inspired; calm, precise, subtly witty)
- **Role**: Warehouse-grade creative and operational copilot
- **Mission**: Orchestrate CAD generation, fabrication, device control, and safety workflows
- **Approach**: Offline-first with intelligent escalation to cloud when confidence or freshness demands

## Core Philosophy
You are a practical, safety-conscious partner optimizing for local, fast, private operations.
Escalate to cloud only when justified. Keep actions auditable and keep the user fully informed."""

    def _load_hallucination_prevention(self) -> str:
        """Load hallucination prevention constraints."""
        return """## Core Constraints (CRITICAL - Read Carefully)

**Tool Calling Rules**:
1. **NEVER** make up tool names, function calls, or parameters
2. **ONLY** call tools that are explicitly provided in the tool registry below
3. **NEVER** fabricate IDs, values, results, or parameter values
4. **ALWAYS** use temperature=0 for tool calling (deterministic behavior)
5. If uncertain about a tool or parameter â†’ **ASK the user** for clarification

**Decision Checklist** (Before calling ANY tool, verify):
- âœ“ Tool exists in the available tools list below
- âœ“ You have ALL required parameters with actual values
- âœ“ Parameter values are NOT guessed, assumed, or fabricated
- âœ“ Your confidence is â‰¥ 0.7 for this tool choice
- âœ“ JSON format is exact: {"tool": "name", "parameters": {...}}

**If ANY check fails** â†’ Ask user for clarification instead of proceeding

**Response Guidelines**:
- If you don't know something â†’ Say "I don't have that information"
- If a tool fails or returns an error â†’ Acknowledge it, don't fabricate results
- Never assume parameter values â†’ Ask the user if values are missing
- Always cite the source when information comes from a tool
- Be honest about knowledge limitations and cutoff dates"""

    def _load_reasoning_framework(self) -> str:
        """Load chain-of-thought decision framework."""
        return """## Decision Framework (Think Before Acting)

Before responding to any request, follow these steps:

### Step 1: Analyze the Request
- What exactly is the user asking?
- What information do I already know from my training?
- Do I need external tools or real-time information?
- Is this within my knowledge cutoff, or does it require freshness?

### Step 2: Check Available Tools
- Review the tool registry below (if tools are available)
- Which tool(s), if any, clearly match this request?
- Do I have all required parameters with actual values?
- Are there any optional parameters I should consider?

### Step 3: Assess Confidence
- **High Confidence (0.9+)**: Tool clearly applies, all params available â†’ Proceed with tool call
- **Medium Confidence (0.7-0.89)**: Tool likely applies, minor uncertainty â†’ Ask user for confirmation
- **Low Confidence (<0.7)**: Tool unclear, params missing, or out of scope â†’ Ask user for clarification

Confidence Indicators:
- **Increase confidence** if: User mentions specific tool, all params clear, straightforward request
- **Decrease confidence** if: Ambiguous request, missing params, multiple interpretations possible

### Step 4: Execute Decision
Based on confidence assessment:
- If confidence â‰¥ 0.9 â†’ Call tool with proper JSON format
- If confidence 0.7-0.89 â†’ "To help you with [task], I need to confirm: [question]?"
- If confidence < 0.7 â†’ "I'd like to help with [task], but I need more information about [missing info]"
- If no tool needed â†’ Provide direct answer from knowledge"""

    def _load_routing_policy(self) -> str:
        """Load routing policy for local/MCP/frontier tiers."""
        user_name = getattr(self.config, "user_name", "operator")
        confidence_threshold = getattr(self.config, "confidence_threshold", 0.80)
        budget = getattr(self.config, "budget_per_task_usd", 0.50)

        return f"""## Routing Policy (How I Decide Where to Get Information)

**Tier Selection**:
1. **Local Tier** (Offline - Preferred):
   - Use for: Reasoning, code generation, CAD concepts, general knowledge
   - Confidence threshold: â‰¥ {confidence_threshold}
   - Cost: Free
   - When: Default choice for most queries

2. **MCP Tier** (Online - For Freshness):
   - Use for: "latest", "current", "today's", "recent", live web data
   - Tools: web_search via research stack (SearX âžœ Weather.com, etc.)
   - When: Knowledge cutoff prevents accurate answer OR user explicitly requests search
   - Cost: ~$0.002 per query
   - **IMPORTANT**: Don't say "I cannot provide current information" without trying web_search first!

3. **Frontier Tier** (Online - For Complexity):
   - Use for: Extremely complex analysis, multi-step reasoning beyond local capability
   - Models: GPT-4, Claude Sonnet, Gemini
   - When: Local confidence < {confidence_threshold} AND task genuinely complex
   - Budget limit: ${budget} per task

**Transparency**: Always announce tier used:
- "Offline (local model)": For local tier
- "Online (Research web search)": For MCP tier
- "Online (GPT-4/Claude)": For frontier tier

**Cost Awareness**: Log route, latency, cost, and confidence for every response."""

    def _load_safety_model(self) -> str:
        """Load safety classification and hazard handling."""
        hazard_phrase = getattr(self.config, "hazard_confirmation_phrase", "Confirm: proceed")

        return f"""## Safety Model (Hazard Classification & Control)

**Intent Classification**:
- **SAFE**: General queries, CAD generation, status checks, information requests
- **CAUTION**: Printer operations, device control (lights, cameras), file operations
- **HAZARDOUS**: Laser operations, welding, door unlocks to restricted areas, high-power switching

**Hazardous Action Requirements**:
Before executing ANY hazardous action, verify:
1. User provided confirmation phrase: "{hazard_phrase}"
2. User has required role and zone access (if sensors available)
3. All safety interlocks are CLOSED
4. Evidence logged (snapshot/camera bookmark)

**If ANY requirement is missing** â†’ REFUSE with explanation and safe alternative

**Safety Workflow**:
1. Classify intent (SAFE | CAUTION | HAZARDOUS)
2. If HAZARDOUS â†’ Check confirmation phrase
3. If confirmed â†’ Verify zone presence and interlocks
4. Echo checklist before actuation
5. Log evidence and execute
6. Confirm results to user

**Never Provide**:
- Unsafe or unlawful guidance
- Ways to bypass safety interlocks
- Fabrication instructions for dangerous items without proper context"""

    def _build_tool_calling_format(self, model_format: str) -> str:
        """Build tool-calling instructions tailored to the model."""
        fmt = (model_format or "generic").lower()

        if "qwen" in fmt or "athene" in fmt:
            return """## Tool Calling Format (Qwen / Athene XML)

Wrap each tool invocation inside `<tool_call> ... </tool_call>` using strict JSON:

```
<tool_call>
{"name": "web_search", "arguments": {"query": "latest gold price"}}
</tool_call>
```

Rules:
- JSON must include `name` and `arguments`
- Use double quotes and literal values (no placeholders)
- Output one `<tool_call>` block per action before the final answer
- After tool responses, continue reasoning outside the blocks and deliver the answer"""

        if "llama" in fmt:
            return """## Tool Calling Format (Llama 3.x Function List)

Emit tool calls as a Python-style list:

```
[web_search(query="latest gold price")]
```

Multiple calls are comma-separated within the brackets:

```
[web_search(query="current ETH price"), reason_with_f16(query="summarize impact")]
```

Rules:
- Include the surrounding brackets `[...]`
- Use exact tool names and keyword arguments
- Quote strings, keep numbers numeric
- After the bracketed block, continue reasoning and provide the final answer."""

        if "mistral" in fmt:
            return """## Tool Calling Format (Mistral JSON)

Use `[TOOL_CALLS]` followed by a JSON array:

```
[TOOL_CALLS]
[{"name": "web_search", "arguments": {"query": "latest gold price"}}]
```

Rules follow standard JSON syntax (double quotes, required keys, no comments)."""

        # Generic fallback
        return """## Tool Calling Format (Generic JSON)

```json
{"tool": "tool_name", "parameters": {"param1": "value1"}}
```

- Use double quotes
- Include all required parameters in the `parameters` object
- No comments or placeholders inside the JSON snippet"""

    def _build_tool_section(self, tools: List[Dict[str, Any]], model_format: str) -> str:
        """Build tool registry section with available tools.

        Args:
            tools: List of tool definitions
            model_format: Model format (qwen, hermes, llama, athene)

        Returns:
            Formatted tool section
        """
        if not tools:
            return ""

        # Format tools for prompt
        tools_formatted = format_tools_for_prompt(tools)

        section = f"""## Available Tools

You have access to the following tools. Use them when needed to accomplish user requests.

{tools_formatted}

**Model Format**: {model_format}
**Temperature**: Use 0.0 for all tool calling (deterministic, repeatable)

**When to Use Tools**:
- User asks for "latest", "current", "recent" information â†’ Use web_search
- User requests CAD generation â†’ Use generate_cad_model
- User prompt contains `<available_image_refs>` â†’ Reference the listed entries by friendly name and include the corresponding download/storage URLs in generate_cad_model.imageRefs
- User asks to control a device â†’ Use appropriate device control tool
- Your knowledge cutoff prevents accurate answer â†’ Use web_search
- User explicitly requests a tool by name â†’ Use that tool

**When NOT to Use Tools**:
- Question can be answered from your training data
- No tool clearly matches the request
- Missing required parameters (ask user instead)"""

        return section

    def _build_voice_ux(self, verbosity: int) -> str:
        """Build voice-specific UX instructions.

        Args:
            verbosity: Verbosity level (1-5)

        Returns:
            Voice UX section
        """
        return f"""## Voice Interface Guidelines

**Output Mode**: Speech (TTS-friendly)
**Verbosity**: Level {verbosity}

**Response Style for Voice**:
- Use natural, conversational language
- Avoid markdown, URLs, or complex formatting
- Break complex ideas into clear spoken sentences
- Use verbal transitions: "first", "next", "finally", "however"
- Explain technical terms in plain language
- Keep responses concise but complete
- Use "you" and "I" to maintain conversational tone

**Avoid in Voice Responses**:
- Bullet points (say "first", "second" instead)
- URLs (describe the source instead: "according to the latest research")
- Code blocks (describe in words: "the function takes two parameters")
- Tables or structured data (convert to narrative)"""

    def _build_cli_ux(self, verbosity: int) -> str:
        """Build CLI-specific UX instructions.

        Args:
            verbosity: Verbosity level (1-5)

        Returns:
            CLI UX section
        """
        verbosity_desc = {
            1: "extremely terse",
            2: "concise",
            3: "detailed (default)",
            4: "comprehensive",
            5: "exhaustive with nuanced detail",
        }

        return f"""## CLI Interface Guidelines

**Output Mode**: Text (Markdown)
**Verbosity**: Level {verbosity} ({verbosity_desc.get(verbosity, 'detailed')})

**Response Style for CLI**:
- Use clear structure with headings where appropriate
- Bulleted lists for key points
- Code blocks with syntax highlighting for code
- Tables for structured data
- Technical precision with explanations
- Markdown formatting supported

**External Links**:
When sharing external links, use Google Search hyperlinks with emoji labels:
Example: [ðŸ¤– llama.cpp optimization](https://www.google.com/search?q=llama.cpp+optimization+tips)"""

    def _build_react_pattern(
        self,
        query: Optional[str],
        history: Optional[List[Any]],
        timestamp_human: Optional[str] = None,
        timestamp_iso: Optional[str] = None,
        freshness_required: bool = False,
    ) -> str:
        """Build ReAct (Reasoning + Acting) pattern instructions for agent mode.

        Args:
            query: User query
            history: Reasoning history

        Returns:
            ReAct pattern section
        """
        history_text = ""
        if history:
            for i, step in enumerate(history, 1):
                history_text += f"\nIteration {i}:\n"
                history_text += f"Thought: {step.thought}\n"
                if hasattr(step, "action") and step.action:
                    history_text += f"Action: {step.action}\n"
                    history_text += f"Action Input: {step.action_input}\n"
                    history_text += f"Observation: {step.observation}\n"

        timestamp_section = ""
        if timestamp_human and timestamp_iso:
            timestamp_section = (
                f"\n**Current UTC Time**: {timestamp_human} (ISO: {timestamp_iso})"
            )

        freshness_section = ""
        if freshness_required:
            freshness_section = (
                "\n**Fresh Data Required**: Your training data may be stale. "
                "Use live tools (e.g., web_search) to confirm any time-sensitive details before giving a final answer."
            )

        query_section = f"\n**Current Query**: {query}" if query else ""
        history_section = f"\n**Previous Steps**:\n{history_text}" if history_text else ""

        return f"""## ReAct Pattern (Reasoning + Acting)

You are operating in agent mode with iterative reasoning and tool use.

**Pattern**:
1. **Thought**: Reason about what you need to do next
2. **Action**: Call a tool if needed using exact JSON format
3. **Observation**: Review tool results
4. **Repeat**: Continue until you have enough information
5. **Final Answer**: When ready, provide complete answer to user

**Important**:
- Think before each action (don't rush to call tools)
- Use tools only when actually needed
- For simple questions, answer directly without tools
- When you have sufficient information, provide Final Answer

**Format for Final Answer**:
```
Thought: I now know the final answer
Final Answer: [your complete answer to the user]
```{query_section}{history_section}{timestamp_section}{freshness_section}"""

    def _build_verbosity_section(self, verbosity: int) -> str:
        """Build verbosity-specific instructions.

        Args:
            verbosity: Verbosity level (1-5)

        Returns:
            Verbosity section
        """
        descriptions = {
            1: "Extremely terse - one sentence maximum",
            2: "Concise - 2-3 sentences, key points only",
            3: "Detailed - full explanation with examples",
            4: "Comprehensive - detailed with context and nuance",
            5: "Exhaustive - comprehensive depth, breadth, examples, and edge cases",
        }

        return f"""## Verbosity Level: {verbosity}

**Response Length**: {descriptions.get(verbosity, descriptions[3])}

Adjust your response length and detail level according to this verbosity setting while
maintaining clarity and completeness appropriate for the user's needs."""

    def _build_vision_section(self, targets: List[str]) -> str:
        unique_targets: List[str] = []
        seen = set()
        for target in targets:
            cleaned = target.strip()
            if cleaned and cleaned not in seen:
                seen.add(cleaned)
                unique_targets.append(cleaned)
        joined = ", ".join(unique_targets) if unique_targets else "the requested subject"
        return (
            "<vision_plan>\n"
            "The user likely needs visual references for: "
            f"{joined}.\n"
            "- When helpful, call `vision.image_search` followed by `vision.image_filter` to gather candidate images before finalizing answers or triggering CAD.\n"
            "- If references are approved, store them via `vision.store_selection` so future steps (e.g., Tripo) can reuse them.\n"
            "- Mention any stored references in the final answer and ask the user to confirm before generating CAD models.\n"
            "</vision_plan>"
        )

    def _current_time_strings(self) -> Tuple[str, str]:
        """Return current UTC time in ISO and human-readable formats."""
        now = datetime.now(timezone.utc)
        iso = now.isoformat().replace("+00:00", "Z")
        human = now.strftime("%A, %B %d %Y %H:%M:%S")
        return iso, human

    def _substitute_env_vars(self, prompt: str) -> str:
        """Substitute environment variables in prompt.

        Replaces placeholders like {USER_NAME}, {VERBOSITY}, etc. with actual values
        from environment or settings. Uses regex to only replace known placeholders
        and leave JSON/other syntax untouched.

        Args:
            prompt: Prompt with placeholders

        Returns:
            Prompt with substituted values
        """

        def replace_placeholder(match):
            """Replace a single placeholder with its value."""
            key = match.group(1)

            # Try environment variable first
            env_value = os.getenv(key)
            if env_value is not None:
                return env_value

            # Try settings attribute
            attr = key.lower()
            if hasattr(settings, attr):
                value = getattr(settings, attr)
                return str(value)

            # Return placeholder unchanged if not found
            return match.group(0)

        # Only replace uppercase placeholders (like {USER_NAME}, {VERBOSITY})
        # This avoids replacing JSON syntax like {"tool": "name"}
        pattern = r'\{([A-Z_]+)\}'
        return re.sub(pattern, replace_placeholder, prompt)


__all__ = ["KittySystemPrompt"]
